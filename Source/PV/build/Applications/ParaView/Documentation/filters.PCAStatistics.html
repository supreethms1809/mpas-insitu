
<html>
    <head>
        <title>Principal Component Analysis</title>
        <meta name="proxy_name" contents="filters.PCAStatistics"/>
        <meta name="filename" contents="filters.PCAStatistics.html"/>
    </head>
    <body>
        <h2>Principal Component Analysis (PCAStatistics)</h2>
        <i>
            <p>Compute a statistical model of a dataset and/or assess the dataset with a statistical model.</p>
        </i>
        <div class="description">
      This filter either computes a statistical model of a dataset or takes
      such a model as its second input. Then, the model (however it is
      obtained) may optionally be used to assess the input dataset. &lt;p&gt;
      This filter performs additional analysis above and beyond the
      multicorrelative filter. It computes the eigenvalues and eigenvectors of
      the covariance matrix from the multicorrelative filter. Data is then
      assessed by projecting the original tuples into a possibly
      lower-dimensional space. &lt;p&gt; Since the PCA filter uses the
      multicorrelative filter's analysis, it shares the same raw covariance
      table specified in the multicorrelative documentation. The second table
      in the multiblock dataset comprising the model output is an expanded
      version of the multicorrelative version. &lt;p&gt; As with the
      multicorrlative filter, the second model table contains the mean values,
      the upper-triangular portion of the symmetric covariance matrix, and the
      non-zero lower-triangular portion of the Cholesky decomposition of the
      covariance matrix. Below these entries are the eigenvalues of the
      covariance matrix (in the column labeled "Mean") and the eigenvectors (as
      row vectors) in an additional NxN matrix.</div>
        <table width="97%" border="2px">
            <tr bgcolor="#9acd32">
                <th>Property</th>
                <th width="60%">Description</th>
                <th width="5%">Default(s)</th>
                <th width="20%">Restrictions</th>
            </tr>
            <tr>
                <th>Input</th>
                <td>The input to the filter. Arrays from this dataset will
        be used for computing statistics and/or assessed by a statistical
        model.</td>
                <td>
                    <span/>
                </td>
                <td>
                    <p>Accepts input of following types:<ul>
                            <li>vtkImageData</li>
                            <li>vtkStructuredGrid</li>
                            <li>vtkPolyData</li>
                            <li>vtkUnstructuredGrid</li>
                            <li>vtkTable</li>
                            <li>vtkGraph</li>
                        </ul>
                    </p>
                    <p>
      The dataset much contain a field array ()
      </p>
                </td>
            </tr>
            <tr>
                <th>ModelInput</th>
                <td>A previously-calculated model with which to assess a
        separate dataset. This input is optional.</td>
                <td>
                    <span/>
                </td>
                <td>
                    <p>Accepts input of following types:<ul>
                            <li>vtkTable</li>
                            <li>vtkMultiBlockDataSet</li>
                        </ul>
                    </p>
                </td>
            </tr>
            <tr>
                <th>AttributeMode</th>
                <td>Specify which type of field data the arrays will be
        drawn from.</td>
                <td>0<span/>
                </td>
                <td>
                    <p>The value must be field array name.</p>
                </td>
            </tr>
            <tr>
                <th>Variables of Interest</th>
                <td>Choose arrays whose entries will be used to form
        observations for statistical analysis.</td>
                <td>
                    <span/>
                </td>
                <td/>
            </tr>
            <tr>
                <th>Task</th>
                <td>Specify the task to be performed: modeling and/or
        assessment. &lt;ol&gt; &lt;li&gt; "Detailed model of input data,"
        creates a set of output tables containing a calculated statistical
        model of the &lt;b&gt;entire&lt;/b&gt; input dataset;&lt;/li&gt;
        &lt;li&gt; "Model a subset of the data," creates an output table (or
        tables) summarizing a &lt;b&gt;randomly-chosen subset&lt;/b&gt; of the
        input dataset;&lt;/li&gt; &lt;li&gt; "Assess the data with a model,"
        adds attributes to the first input dataset using a model provided on
        the second input port; and&lt;/li&gt; &lt;li&gt; "Model and assess the
        same data," is really just operations 2 and 3 above applied to the same
        input dataset. The model is first trained using a fraction of the input
        data and then the entire dataset is assessed using that
        model.&lt;/li&gt; &lt;/ol&gt; When the task includes creating a model
        (i.e., tasks 2, and 4), you may adjust the fraction of the input
        dataset used for training. You should avoid using a large fraction of
        the input data for training as you will then not be able to detect
        overfitting. The &lt;i&gt;Training fraction&lt;/i&gt; setting will be
        ignored for tasks 1 and 3.</td>
                <td>3<span/>
                </td>
                <td>
                    <p>The value(s) is an enumeration of the following:<ul>
                            <li>Detailed model of input data (0)</li>
                            <li>Model a subset of the data (1)</li>
                            <li>Assess the data with a model (2)</li>
                            <li>Model and assess the same data (3)</li>
                        </ul>
                    </p>
                </td>
            </tr>
            <tr>
                <th>TrainingFraction</th>
                <td>Specify the fraction of values from the input dataset to
        be used for model fitting. The exact set of values is chosen at random
        from the dataset.</td>
                <td>0.1<span/>
                </td>
                <td/>
            </tr>
            <tr>
                <th>Normalization Scheme</th>
                <td>Before the eigenvector decomposition of the covariance
        matrix takes place, you may normalize each (i,j) entry by sqrt(
        cov(i,i) * cov(j,j) ). This implies that the variance of each variable
        of interest should be of equal importance.</td>
                <td>2<span/>
                </td>
                <td>
                    <p>The value(s) is an enumeration of the following:<ul>
                            <li>No normalization (0)</li>
                            <li>Normalize using covariances (3)</li>
                        </ul>
                    </p>
                </td>
            </tr>
            <tr>
                <th>Basis Scheme</th>
                <td>When reporting assessments, should the full eigenvector
        decomposition be used to project the original vector into the new space
        (Full basis), or should a fixed subset of the decomposition be used
        (Fixed-size basis), or should the projection be clipped to preserve at
        least some fixed "energy" (Fixed-energy basis)?&lt;p&gt; As an example,
        suppose the variables of interest were {A,B,C,D,E} and that the
        eigenvalues of the covariance matrix for these were {5,2,1.5,1,.5}. If
        the "Full basis" scheme is used, then all 5 components of the
        eigenvectors will be used to project each {A,B,C,D,E}-tuple in the
        original data into a new 5-components space.&lt;p&gt; If the
        "Fixed-size" scheme is used and the "Basis Size" property is set to 4,
        then only the first 4 eigenvector components will be used to project
        each {A,B,C,D,E}-tuple into the new space and that space will be of
        dimension 4, not 5.&lt;p&gt; If the "Fixed-energy basis" scheme is used
        and the "Basis Energy" property is set to 0.8, then only the first 3
        eigenvector components will be used to project each {A,B,C,D,E}-tuple
        into the new space, which will be of dimension 3. The number 3 is
        chosen because 3 is the lowest N for which the sum of the first N
        eigenvalues divided by the sum of all eigenvalues is larger than the
        specified "Basis Energy" (i.e., (5+2+1.5)/10 = 0.85 &gt;
        0.8).</td>
                <td>0<span/>
                </td>
                <td>
                    <p>The value(s) is an enumeration of the following:<ul>
                            <li>Full basis (0)</li>
                            <li>Fixed-size basis (1)</li>
                            <li>Fixed-energy basis (2)</li>
                        </ul>
                    </p>
                </td>
            </tr>
            <tr>
                <th>Basis Size</th>
                <td>The maximum number of eigenvector components to use when
        projecting into the new space.</td>
                <td>2<span/>
                </td>
                <td/>
            </tr>
            <tr>
                <th>Basis Energy</th>
                <td>The minimum energy to use when determining the
        dimensionality of the new space into which the assessment will project
        tuples.</td>
                <td>0.1<span/>
                </td>
                <td/>
            </tr>
            <tr>
                <th>RobustPCA</th>
                <td>Compute robust PCA with medians instead of means.</td>
                <td>0<span/>
                </td>
                <td>
                    <p>Accepts boolean values (0 or 1).</p>
                </td>
            </tr>
        </table>
    </body>
</html>